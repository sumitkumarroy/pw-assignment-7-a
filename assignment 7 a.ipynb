{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d14e2bc",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "Web scraping is the process of extracting data from websites. It involves fetching the HTML content of a webpage and then parsing it to extract the desired information, such as text, images, links, or structured data. Web scraping is used for various purposes, including:\n",
    "\n",
    "Market Research: Companies use web scraping to gather data on competitor prices, product information, and customer reviews to inform their market strategies.\n",
    "Data Aggregation: Web scraping is used to aggregate data from multiple sources on the web, such as news articles, social media posts, or job listings, to create comprehensive datasets.\n",
    "Lead Generation: Businesses scrape websites to collect contact information, such as email addresses or phone numbers, for potential leads or customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5684ef",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "There are several methods for web scraping, including:\n",
    "\n",
    "Using Libraries: Python libraries like BeautifulSoup, Scrapy, or Selenium provide powerful tools for web scraping. These libraries handle HTTP requests, HTML parsing, and DOM traversal, making scraping easier and more efficient.\n",
    "APIs: Some websites offer APIs (Application Programming Interfaces) that allow developers to access data in a structured format without needing to scrape HTML. Using APIs is generally more reliable and efficient than scraping raw HTML.\n",
    "Custom Scripts: Developers can write custom scripts in languages like Python, JavaScript, or Ruby to scrape websites directly. This method requires more coding effort and may be less robust than using specialized libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8b80a",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Beautiful Soup is a Python library for parsing HTML and XML documents. It provides a simple interface for navigating and searching the parse tree created from the HTML content of a webpage. Beautiful Soup is used for web scraping because:\n",
    "\n",
    "It simplifies the process of extracting data from HTML by providing intuitive methods for navigating the DOM (Document Object Model).\n",
    "It handles malformed HTML gracefully, allowing developers to extract data even from poorly structured web pages.\n",
    "It integrates well with other Python libraries like requests for fetching web pages, making it a versatile tool for web scraping tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d4c98",
   "metadata": {},
   "source": [
    "Q4. Why is Flask used in this Web Scraping project?\n",
    "\n",
    "Flask is a lightweight web framework for Python that is commonly used for building web applications and APIs. In a web scraping project, Flask might be used for various purposes:\n",
    "\n",
    "API Endpoints: Flask can be used to create RESTful APIs for serving scraped data to client applications or other services.\n",
    "Frontend Interface: Flask can serve as a backend for a web application that interacts with the scraped data, providing a user interface for searching, filtering, or visualizing the data.\n",
    "Background Tasks: Flask can handle background tasks, such as scheduling periodic scrapes or processing scraped data asynchronously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81178b2a",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service\n",
    "\n",
    "In a web scraping project deployed on AWS, several services might be used:\n",
    "\n",
    "Amazon EC2 (Elastic Compute Cloud): EC2 provides scalable virtual servers in the cloud. It might be used to host the web scraping application or any backend services needed for data processing.\n",
    "\n",
    "Amazon S3 (Simple Storage Service): S3 is an object storage service that can be used to store scraped data, images, or any other files generated during the scraping process.\n",
    "\n",
    "Amazon RDS (Relational Database Service): RDS offers managed relational databases in the cloud. It might be used to store structured data extracted from web pages, providing a scalable and reliable storage solution.\n",
    "\n",
    "Amazon CloudWatch: CloudWatch provides monitoring and logging services for AWS resources. It can be used to monitor the performance of EC2 instances, track application logs, and set up alarms for critical events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d56682e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
